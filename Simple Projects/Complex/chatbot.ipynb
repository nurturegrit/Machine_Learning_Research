{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7319f0a1-ad05-42fb-a30c-01294dd47022",
   "metadata": {},
   "source": [
    "Certainly! Let's create an even more complex project involving multiple advanced stages of machine learning and data science. We will work on building an End-to-End Conversation System (Chatbot) using Natural Language Processing (NLP) and Reinforcement Learning (RL) for dialogue management. This project involves various stages and integrations, tackling cutting-edge concepts and techniques.\n",
    "Project Overview: Intelligent Conversational Agent\n",
    "\n",
    "    Problem Definition: Building an end-to-end conversational agent.\n",
    "    Data Collection and Preprocessing: Collecting and preprocessing conversation datasets.\n",
    "    Natural Language Understanding (NLU): Creating a model to understand user intents and entities.\n",
    "    Dialogue State Management: Using a dialogue state manager to handle context.\n",
    "    Natural Language Generation (NLG): Generating human-like responses.\n",
    "    Reinforcement Learning for Dialogue Management: Improving the conversation flow.\n",
    "    Deployment: Building an API for the chatbot.\n",
    "    Evaluation and Fine-tuning: Using metrics and user feedback to improve performance.\n",
    "\n",
    "Step 1: Define the Problem\n",
    "\n",
    "Objective: Build a conversational agent that understands user input, manages dialogue context, and provides meaningful responses.\n",
    "Step 2: Data Collection and Preprocessing\n",
    "\n",
    "We will use the Cornell Movie-Dialogs Corpus for building our conversational agent.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Download and load the dataset\n",
    "!curl -O http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip\n",
    "!unzip cornell_movie_dialogs_corpus.zip\n",
    "\n",
    "# Load dialogues\n",
    "lines = open('cornell movie-dialogs corpus/movie_lines.txt', encoding='utf-8', errors='ignore').read().split('\\n')\n",
    "conversations = open('cornell movie-dialogs corpus/movie_conversations.txt', encoding='utf-8', errors='ignore').read().split('\\n')\n",
    "\n",
    "# Preprocess data\n",
    "id2line = {line.split(' +++$+++ ')[0]: line.split(' +++$+++ ')[-1] for line in lines}\n",
    "conversation_ids = [conv.split(' +++$+++ ')[-1][1:-1].replace(\"'\", \"\").replace(\" \", \"\").split(',') for conv in conversations]\n",
    "\n",
    "# Extracting pairs of sentences\n",
    "dialogue_pairs = [(id2line[c[0]], id2line[c[1]]) for c in conversation_ids if len(c) > 1]\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(dialogue_pairs, columns=['input', 'response'])\n",
    "print(df.head())\n",
    "\n",
    "Step 3: Natural Language Understanding (NLU)\n",
    "\n",
    "We'll use a Recurrent Neural Network (RNN) with an attention mechanism to understand user intents and entities.\n",
    "\n",
    "    Tokenization and Sequencing: Convert text to sequences.\n",
    "    Word Embeddings: Use pre-trained embeddings like GloVe.\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, Bidirectional\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Tokenization\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df['input'])\n",
    "input_sequences = tokenizer.texts_to_sequences(df['input'])\n",
    "response_sequences = tokenizer.texts_to_sequences(df['response'])\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Padding\n",
    "input_sequences = pad_sequences(input_sequences, padding='post')\n",
    "response_sequences = pad_sequences(response_sequences, padding='post')\n",
    "\n",
    "# Model\n",
    "embedding_dim = 100\n",
    "latent_dim = 256\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "encoder_embedding = Embedding(input_dim=vocab_size, output_dim=embedding_dim)(encoder_inputs)\n",
    "encoder_lstm = Bidirectional(LSTM(latent_dim, return_state=True, dropout=0.5))\n",
    "encoder_outputs, forward_h, forward_c, backward_h, backward_c = encoder_lstm(encoder_embedding)\n",
    "state_h = tf.keras.layers.Concatenate()([forward_h, backward_h])\n",
    "state_c = tf.keras.layers.Concatenate()([forward_c, backward_c])\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Decoder\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "decoder_embedding = Embedding(input_dim=vocab_size, output_dim=embedding_dim)(decoder_inputs)\n",
    "decoder_lstm = LSTM(latent_dim*2, return_sequences=True, return_state=True, dropout=0.5)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "decoder_dense = Dense(vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Seq2Seq Model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "model.summary()\n",
    "\n",
    "# Training\n",
    "input_sequences_shifted = np.zeros_like(input_sequences)\n",
    "input_sequences_shifted[:, :-1] = input_sequences[:, 1:]\n",
    "\n",
    "history = model.fit([input_sequences, input_sequences_shifted], \n",
    "                     response_sequences, \n",
    "                     batch_size=64, \n",
    "                     epochs=100, \n",
    "                     validation_split=0.2)\n",
    "\n",
    "Step 4: Dialogue State Management\n",
    "\n",
    "We use a state tracker to maintain conversational context.\n",
    "\n",
    "class DialogueStateTracker:\n",
    "    def __init__(self):\n",
    "        self.slots = {}\n",
    "\n",
    "    def update(self, intent, entities):\n",
    "        self.slots.update(entities)\n",
    "        print(f\"Current State: {self.slots}\")\n",
    "\n",
    "state_tracker = DialogueStateTracker()\n",
    "state_tracker.update(\"book_flight\", {\"destination\": \"New York\", \"date\": \"2023-12-01\"})\n",
    "\n",
    "Step 5: Natural Language Generation (NLG)\n",
    "\n",
    "Using generative models to produce human-like responses.\n",
    "\n",
    "def respond(input_text):\n",
    "    input_sequence = tokenizer.texts_to_sequences([input_text])\n",
    "    input_sequence = pad_sequences(input_sequence, maxlen=input_sequences.shape[1], padding='post')\n",
    "    output_sequence = np.zeros((1, input_sequences.shape[1]))\n",
    "    output_sequence[0, 0] = tokenizer.word_index['start']\n",
    "\n",
    "    for i in range(1, input_sequences.shape[1]):\n",
    "        output_tokens = model.predict([input_sequence, output_sequence])\n",
    "        sampled_token_idx = np.argmax(output_tokens[0, i - 1, :])\n",
    "        if sampled_token_idx == 0:\n",
    "            break\n",
    "        output_sequence[0, i] = sampled_token_idx\n",
    "        sampled_word = tokenizer.index_word[sampled_token_idx]\n",
    "        if sampled_word == 'end':\n",
    "            break\n",
    "    \n",
    "    response = ' '.join([tokenizer.index_word[idx] for idx in output_sequence[0] if idx != 0])\n",
    "    return response\n",
    "\n",
    "# Example usage\n",
    "print(respond(\"Hello, how are you?\"))\n",
    "\n",
    "Step 6: Reinforcement Learning for Dialogue Management\n",
    "\n",
    "Implementing reinforcement learning to optimize dialogue strategy.\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "class ReinforcementLearningChatbot:\n",
    "    def __init__(self, model, state_tracker):\n",
    "        self.model = model\n",
    "        self.state_tracker = state_tracker\n",
    "        self.optimizer = Adam()\n",
    "        self.gamma = 0.99  # Discount factor\n",
    "\n",
    "    def act(self, state):\n",
    "        predicted_q_values = self.model.predict(state)\n",
    "        action = np.argmax(predicted_q_values[0])\n",
    "        return action\n",
    "\n",
    "    def train(self, state, action, reward, next_state, done):\n",
    "        target = reward\n",
    "        if not done:\n",
    "            next_q_values = self.model.predict(next_state)\n",
    "            target = reward + self.gamma * np.max(next_q_values[0])\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            q_values = self.model(state)\n",
    "            q_value = q_values[0][action]\n",
    "            loss = K.mean(K.square(target - q_value))\n",
    "\n",
    "        grads = tape.gradient(loss, self.model.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.model.trainable_variables))\n",
    "\n",
    "# Example interaction (mock)\n",
    "state = np.array([[1, 2, 3, 4]])  # Mock state\n",
    "next_state = np.array([[1, 2, 3, 4]])  # Mock next state\n",
    "action = 0  # Mock action\n",
    "reward = 1  # Mock reward\n",
    "done = True  # Mock terminal state\n",
    "\n",
    "rl_chatbot = ReinforcementLearningChatbot(model, state_tracker)\n",
    "rl_chatbot.train(state, action, reward, next_state, done)\n",
    "\n",
    "Step 7: Deployment\n",
    "\n",
    "Deploy the chatbot using Flask API.\n",
    "\n",
    "from flask import Flask, request, jsonify\n",
    "\n",
    "app = Flask(__name__)\n",
    "chatbot = ReinforcementLearningChatbot(model, state_tracker)\n",
    "\n",
    "@app.route('/chat', methods=['POST'])\n",
    "def chat():\n",
    "    user_message = request.json['message']\n",
    "    response = respond(user_message)\n",
    "    return jsonify({'response': response})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(port=5000, debug=True)\n",
    "\n",
    "Step 8: Evaluation and Fine-Tuning\n",
    "\n",
    "Evaluate the model using various metrics and continuously improve based on user feedback.\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Assuming you have test datasets\n",
    "y_true = [...]  # True responses\n",
    "y_pred = [...]\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "print(\"F1 Score:\", f1_score(y_true, y_pred, average='weighted'))\n",
    "\n",
    "Further Steps and Hands-On Tips\n",
    "\n",
    "    Custom Dataset: Use your own conversational data.\n",
    "    Complex Dialogue Policies: Implement more advanced policies with reinforcement learning.\n",
    "    Multi-turn Conversations: Handle multi-turn conversations with context management.\n",
    "    Metrics: Track custom metrics like Conversation Success Rate (CSR) and User Satisfaction Score (USS).\n",
    "    Scalability: Scale the API using cloud platforms like AWS or GCP.\n",
    "\n",
    "Additional Resources\n",
    "\n",
    "    Rasa: https://rasa.com/\n",
    "    OpenAI GPT Models: https://beta.openai.com/docs/\n",
    "    Deep Reinforcement Learning Tutorials: https://spinningup.openai.com/en/latest/\n",
    "    Flask Documentation: https://flask.palletsprojects.com/en/2.0.x/\n",
    "\n",
    "Feel free to ask more questions or request more details on specific components, and let's ensure you are comfortable with each concept before moving forward!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05932c4e-6c00-4e9c-bdec-6d7104be738c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
