{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77376025-305f-4124-ba05-37ee846a1e6f",
   "metadata": {},
   "source": [
    "Absolutely, let's dive into a more complex project. How about building a machine learning model to predict house prices using the famous \"California Housing Prices\" dataset? This project will involve the following steps:\n",
    "\n",
    "    Understanding the problem\n",
    "    Loading and exploring the data\n",
    "    Preprocessing the data\n",
    "    Building and training a machine learning model\n",
    "    Evaluating the model\n",
    "    Fine-tuning the model for better performance\n",
    "    Making predictions with the model\n",
    "\n",
    "Understanding the Problem\n",
    "\n",
    "The goal is to predict the median house value for each district in California, based on a mix of features.\n",
    "Dataset Features\n",
    "\n",
    "    Longitude\n",
    "    Latitude\n",
    "    Housing Median Age\n",
    "    Total Rooms\n",
    "    Total Bedrooms\n",
    "    Population\n",
    "    Households\n",
    "    Median Income\n",
    "    Median House Value (target variable)\n",
    "\n",
    "Step 1: Setting Up Your Environment\n",
    "\n",
    "Make sure you have the following libraries installed:\n",
    "\n",
    "pip install pandas numpy scikit-learn matplotlib seaborn\n",
    "\n",
    "Step 2: Loading and Exploring the Data\n",
    "\n",
    "First, letâ€™s load the dataset and explore it.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://raw.githubusercontent.com/ageron/handson-ml/master/datasets/housing/housing.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(df.head())\n",
    "\n",
    "# Display basic statistics\n",
    "print(df.describe())\n",
    "\n",
    "# Check for missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "Step 3: Visualizing the Data\n",
    "\n",
    "Understanding the data through visualization is crucial.\n",
    "\n",
    "# Scatter plot of median income vs. median house value\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df['median_income'], df['median_house_value'], alpha=0.1)\n",
    "plt.xlabel('Median Income')\n",
    "plt.ylabel('Median House Value')\n",
    "plt.title('Median Income vs Median House Value')\n",
    "plt.show()\n",
    "\n",
    "# Correlation matrix\n",
    "corr_matrix = df.corr()\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n",
    "\n",
    "Step 4: Preprocessing the Data\n",
    "\n",
    "We'll handle missing values, encode categorical variables, and normalize numeric features.\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Handling missing values in 'total_bedrooms'\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "df['total_bedrooms'] = imputer.fit_transform(df[['total_bedrooms']])\n",
    "\n",
    "# Separating features and target variable\n",
    "X = df.drop('median_house_value', axis=1)\n",
    "y = df['median_house_value']\n",
    "\n",
    "# Encode categorical feature (\"ocean_proximity\")\n",
    "cat_features = [\"ocean_proximity\"]\n",
    "cat_transformer = OneHotEncoder()\n",
    "\n",
    "# Standardizing numerical features\n",
    "num_features = X.drop(\"ocean_proximity\", axis=1).columns\n",
    "num_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Combining transformers\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_transformer, num_features),\n",
    "        ('cat', cat_transformer, cat_features)\n",
    "    ])\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "Step 5: Building and Training the Model\n",
    "\n",
    "We'll use a more sophisticated model, a Random Forest Regressor.\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Create a pipeline for the data processing and model\n",
    "model_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "Step 6: Evaluating the Model\n",
    "\n",
    "We'll evaluate the model's performance on the test set.\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model_pipeline.predict(X_test)\n",
    "\n",
    "# Calculate performance metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"Root Mean Squared Error: {rmse}\")\n",
    "\n",
    "Step 7: Fine-Tuning the Model\n",
    "\n",
    "We'll use GridSearchCV to fine-tune the hyperparameters of the RandomForestRegressor.\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'regressor__n_estimators': [50, 100, 200],\n",
    "    'regressor__max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Create the grid search\n",
    "grid_search = GridSearchCV(model_pipeline, param_grid, cv=3, scoring='neg_mean_squared_error', verbose=2, n_jobs=-1)\n",
    "\n",
    "# Run the grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Best estimator\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the best model\n",
    "y_best_pred = best_model.predict(X_test)\n",
    "best_rmse = np.sqrt(mean_squared_error(y_test, y_best_pred))\n",
    "\n",
    "print(f\"Best Root Mean Squared Error: {best_rmse}\")\n",
    "\n",
    "Step 8: Making Predictions\n",
    "\n",
    "Finally, you can use your best model to make predictions on new data.\n",
    "\n",
    "# Example new data\n",
    "new_data = pd.DataFrame({\n",
    "    'longitude': [-122.23],\n",
    "    'latitude': [37.88],\n",
    "    'housing_median_age': [41.0],\n",
    "    'total_rooms': [880.0],\n",
    "    'total_bedrooms': [129.0],\n",
    "    'population': [322.0],\n",
    "    'households': [126.0],\n",
    "    'median_income': [8.3252],\n",
    "    'ocean_proximity': ['NEAR BAY']\n",
    "})\n",
    "\n",
    "# Make prediction\n",
    "predicted_value = best_model.predict(new_data)\n",
    "print(f\"Predicted Median House Value: {predicted_value[0]}\")\n",
    "\n",
    "Conclusion\n",
    "\n",
    "Congratulations! You've built a more complex machine learning model to predict house prices using the California Housing Prices dataset. You've learned how to preprocess data, build and train a model, evaluate and fine-tune it, and make predictions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419ab60a-1fd5-45a6-bb21-5544282674c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
